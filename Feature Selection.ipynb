{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "explicit-bubble",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as mpl\n",
    "import math \n",
    "import seaborn as sea\n",
    "import statistics\n",
    "from scipy import stats\n",
    "from numpy import percentile\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import load_boston\n",
    "import matplotlib\n",
    "import statsmodels.api as sm\n",
    "%matplotlib inline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "known-donna",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracyscore(X,Y):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)  \n",
    "    warnings.simplefilter('ignore')\n",
    "    LR = LogisticRegression()\n",
    "    KNN = KNeighborsClassifier()\n",
    "    NB = GaussianNB()\n",
    "    LSVM = LinearSVC()\n",
    "    NLSVM = SVC(kernel='rbf')\n",
    "    DT = DecisionTreeClassifier()\n",
    "    RF = RandomForestClassifier()\n",
    "    #\n",
    "    LR_fit = LR.fit(X_train, Y_train)\n",
    "    KNN_fit = KNN.fit(X_train, Y_train)\n",
    "    NB_fit = NB.fit(X_train, Y_train)\n",
    "    LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "    NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "    DT_fit = DT.fit(X_train, Y_train)\n",
    "    RF_fit = RF.fit(X_train, Y_train)\n",
    "    #\n",
    "    LR_pred = LR_fit.predict(X_test)\n",
    "    KNN_pred = KNN_fit.predict(X_test)\n",
    "    NB_pred = NB_fit.predict(X_test)\n",
    "    LSVM_pred = LSVM_fit.predict(X_test)\n",
    "    NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "    DT_pred = DT_fit.predict(X_test)\n",
    "    RF_pred = RF_fit.predict(X_test)\n",
    "    #\n",
    "    print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "    #\n",
    "    print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "    #\n",
    "    print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "    #\n",
    "    print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "    #\n",
    "    print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "    #\n",
    "    print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "    #\n",
    "    print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "simplified-learning",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank = read_csv('BankChurnML.csv')\n",
    "del bank[\"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2\"]\n",
    "del bank[\"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1\"]\n",
    "X = bank.drop(\"Attrition_Flag\",1)    \n",
    "Y = bank[\"Attrition_Flag\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-cleaners",
   "metadata": {},
   "source": [
    "# Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "elect-guarantee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding constant column of ones, mandatory for sm.OLS model\n",
    "X = bank.drop(\"Attrition_Flag\",1)    #Feature Matrix\n",
    "Y = bank[\"Attrition_Flag\"]           #Target Variable\n",
    "\n",
    "X_1 = sm.add_constant(X)\n",
    "#Fitting sm.OLS model\n",
    "model = sm.OLS(Y,X_1).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "brave-cable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 89.826041 percent accurate\n",
      "KNN is 86.188719 percent accurate\n",
      "Naive Bayes is 87.295730 percent accurate\n",
      "Linear SVMs is 89.562467 percent accurate\n",
      "Non Linear SVMs is 89.246178 percent accurate\n",
      "Decision Trees is 92.409067 percent accurate\n",
      "Random Forests is 95.044808 percent accurate\n"
     ]
    }
   ],
   "source": [
    "cols = list(X.columns)\n",
    "pmax = 1\n",
    "while (len(cols)>0):\n",
    "    p= []\n",
    "    X_1 = X[cols]\n",
    "    X_1 = sm.add_constant(X_1)\n",
    "    model = sm.OLS(Y,X_1).fit()\n",
    "    p = pd.Series(model.pvalues.values[1:],index = cols)      \n",
    "    pmax = max(p)\n",
    "    feature_with_p_max = p.idxmax()\n",
    "    if(pmax>0.05):\n",
    "        cols.remove(feature_with_p_max)\n",
    "    else:\n",
    "        break\n",
    "selected_features_BE = cols\n",
    "X2 = bank[selected_features_BE]\n",
    "accuracyscore(X2,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-hughes",
   "metadata": {},
   "source": [
    "# Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "unnecessary-trail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum number of features: 16\n",
      "Score with 16 features: 0.374021\n",
      "Index(['Gender', 'Months_on_book', 'Total_Relationship_Count',\n",
      "       'Months_Inactive_12_mon', 'Contacts_Count_12_mon',\n",
      "       'Total_Revolving_Bal', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',\n",
      "       'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1'],\n",
      "      dtype='object')\n",
      "(9485, 10)\n",
      "Logistic Regression is 91.407486 percent accurate\n",
      "KNN is 91.249341 percent accurate\n",
      "Naive Bayes is 88.877174 percent accurate\n",
      "Linear SVMs is 91.618345 percent accurate\n",
      "Non Linear SVMs is 90.774908 percent accurate\n",
      "Decision Trees is 94.359515 percent accurate\n",
      "Random Forests is 96.731682 percent accurate\n"
     ]
    }
   ],
   "source": [
    "X = bank.drop(\"Attrition_Flag\",1)    #Feature Matrix\n",
    "y = bank[\"Attrition_Flag\"]           #Target Variable\n",
    "\n",
    "model = LinearRegression()\n",
    "#Initializing RFE model\n",
    "rfe = RFE(model, 7)\n",
    "#Transforming data using RFE\n",
    "X_rfe = rfe.fit_transform(X,y)  \n",
    "#Fitting the data to model\n",
    "model.fit(X_rfe,y)\n",
    "\n",
    "#no of features\n",
    "nof_list=np.arange(1,20)            \n",
    "high_score=0\n",
    "#Variable to store the optimum features\n",
    "nof=0           \n",
    "score_list =[]\n",
    "for n in range(len(nof_list)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0)\n",
    "    model = LinearRegression()\n",
    "    rfe = RFE(model,nof_list[n])\n",
    "    X_train_rfe = rfe.fit_transform(X_train,y_train)\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "    model.fit(X_train_rfe,y_train)\n",
    "    score = model.score(X_test_rfe,y_test)\n",
    "    score_list.append(score)\n",
    "    if(score>high_score):\n",
    "        high_score = score\n",
    "        nof = nof_list[n]\n",
    "print(\"Optimum number of features: %d\" %nof)\n",
    "print(\"Score with %d features: %f\" % (nof, high_score))\n",
    "\n",
    "cols = list(X.columns)\n",
    "model = LinearRegression()\n",
    "#Initializing RFE model\n",
    "rfe = RFE(model, 10)             \n",
    "#Transforming data using RFE\n",
    "X_rfe = rfe.fit_transform(X,y)  \n",
    "#Fitting the data to model\n",
    "model.fit(X_rfe,y)              \n",
    "temp = pd.Series(rfe.support_,index = cols)\n",
    "selected_features_rfe = temp[temp==True].index\n",
    "print(selected_features_rfe)\n",
    "\n",
    "X3 = bank[selected_features_rfe]\n",
    "print(X3.shape)\n",
    "accuracyscore(X3,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-canon",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
